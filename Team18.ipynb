{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c3d2f91-1f6f-4b8a-be8c-eb673e74ef6d",
   "metadata": {},
   "source": [
    "# CS4248 NLP Project Team 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e0af41-f2e7-40e9-850a-a08f76908f4e",
   "metadata": {},
   "source": [
    "## Installing necessary libraries\n",
    "\n",
    "*Note*: Put libraries that need to be installed with `!pip install LIBRARY` so that we can ensure consistency in packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd8a95b-3cc9-48bc-b669-479e3a06b97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from scikit-learn) (3.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (0.45.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from shap) (1.4.1.post1)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from shap) (2.2.1)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from shap) (4.66.2)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from shap) (24.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: numba in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from shap) (0.59.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from shap) (3.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from numba->shap) (0.42.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from scikit-learn->shap) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from scikit-learn->shap) (3.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textstat in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (0.7.3)\n",
      "Requirement already satisfied: pyphen in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from textstat) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from nltk>=3.8->textblob) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from nltk>=3.8->textblob) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from nltk>=3.8->textblob) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install tensorflow\n",
    "!pip install shap\n",
    "!pip install nltk\n",
    "!pip install textstat\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2ec018-9497-4f30-ba5a-510448a46f98",
   "metadata": {},
   "source": [
    "## Constants\n",
    "\n",
    "Please run this cell. Some constants you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc05079b-fb12-4008-b58a-55a905d2d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data consists of text (feature) + classification (y value: 1/2/3/4)\n",
    "TEXT_FEATURE_NAME = \"text\"\n",
    "CLASSIFICATION_NAME = \"classification\"\n",
    "\n",
    "# CONSTANTS\n",
    "classifier_mapping = {\n",
    "    1: \"Satire\",\n",
    "    2: \"Hoax\",\n",
    "    3: \"Propaganda\",\n",
    "    4: \"Reliable News\"\n",
    "}\n",
    "mapping_df = pd.DataFrame(list(classifier_mapping.items()), columns=['classification', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92acb502-671c-441a-b82c-29a5edd337e4",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d708b-196a-4d1d-9e14-9122e262b1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_FILEPATH = \"raw_data/fulltrain.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_FILEPATH, header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb0bcc-8239-4c2f-9221-2db9907c189b",
   "metadata": {},
   "source": [
    "### Breakdown of text classifications (Satire / Hoax / Propoganda / Reliable News)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48003e8a-7bfb-42fa-a0d2-e5244930d200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "value_counts = df[0].value_counts()\n",
    "value_counts.plot(kind='bar')\n",
    "plt.xlabel('Classification')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Breakdown of Text Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79b1f22-da30-4418-b892-bbe1688d48e8",
   "metadata": {},
   "source": [
    "**Analysis**: We can clearly see that the data is unbalanced. False positive implies that we may classify hoax as reliable news \n",
    "and false negatives implies that we may classify reliable news as satire/propaganda/hoax. Depending on the news, our model needs reduce both false negative and false positive. Hence instead of using precision or recall, we will be using macro F1 as the evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ed9d39-f39b-461b-a411-f16338aa45f0",
   "metadata": {},
   "source": [
    "### Analysis of features proposed for feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac6a316-059c-4ea6-b256-301faf991700",
   "metadata": {},
   "source": [
    "In this section, we came up with the following features:\n",
    "\n",
    "- **Readability**\n",
    "\n",
    "    **Hypothesis**: Hoaxes are used to deceive people. Usually people who do not read critically their sources tend to believe hoaxes, hence language would be simpler to understand. Words may be used more crudely.\n",
    "\n",
    "    **Actual**: \n",
    "\n",
    "- **Token Count**\n",
    "\n",
    "    **Hypothesis**: Hoaxes tend to be shorter possibly due to shorter attention span. Informative sources tend to be longer due to details that need to be reported\n",
    "\n",
    "    **Actual**: In reality, this feature may not be useful because the text varies depending on the document. The \"text\" data can be variable number of sentences, so it is not meaningful to use to differentiate classification. In particular, propaganda have a max count of 130,000+ tokens compared to the rest at max of 2000-5000. Propoganda includes websites as well which may artificially prolong the sentence. Thus, if we wish to use token counts, it needs to be standardise per sentence and websites link need to be handled so they do not artifically bloat up the token count.\n",
    "\n",
    "- **Polarity**\n",
    "\n",
    "    **Hypothesis**: Hoaxes are used to deceive people. Usually people who do not read critically their sources tend to believe hoaxes, hence language could be simpler.\n",
    "\n",
    "    **Actual**: \n",
    "\n",
    "- **Subjectivity**\n",
    "\n",
    "    **Hypothesis**: Hoaxes are used to deceive people. Usually people who do not read critically their sources tend to believe hoaxes, hence language could be simpler.\n",
    "\n",
    "    **Actual**: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53a0a98-3d53-4825-a32c-e76c109711d4",
   "metadata": {},
   "source": [
    "#### Utility Functions\n",
    "\n",
    "Please run this cell below before running any of the cells within data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15c6e945-9062-4c63-970b-3ad4c28e4296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_add_column(df, process_func, input_col_name, new_col_name):\n",
    "    selected_col = df[input_col_name]\n",
    "    new_col = selected_col.apply(process_func)\n",
    "    df[new_col_name] = new_col\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_summary_statistics_by_classifier(df, classifier_column, numerical_column):\n",
    "    aggregations = {\n",
    "        numerical_column: ['median', lambda x: x.quantile(0.25), lambda x: x.quantile(0.75), 'min', 'max', 'mean']\n",
    "    }\n",
    "\n",
    "    summary_stats = df.groupby(classifier_column).agg(aggregations)\n",
    "    summary_stats.columns = [col[0] + \"_\" + col[1] for col in summary_stats.columns.values]\n",
    "    merged_df = pd.merge(summary_stats, mapping_df, on=CLASSIFICATION_NAME)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe17a9a9-af51-4a3a-95eb-f52667bff70e",
   "metadata": {},
   "source": [
    "#### Feature Engineering Creation (raw_data/fulltrain.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "005c1253-1d0f-4c0c-9dfa-4de198657781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A little less than a decade ago, hockey fans w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The writers of the HBO series The Sopranos too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Despite claims from the TV news outlet to offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>After receiving 'subpar' service and experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classification                                               text\n",
       "0               1  A little less than a decade ago, hockey fans w...\n",
       "1               1  The writers of the HBO series The Sopranos too...\n",
       "2               1  Despite claims from the TV news outlet to offe...\n",
       "3               1  After receiving 'subpar' service and experienc...\n",
       "4               1  After watching his beloved Seattle Mariners pr..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_FILEPATH = \"raw_data/fulltrain.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_FILEPATH, header=None, names=[CLASSIFICATION_NAME, TEXT_FEATURE_NAME])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9303a3b-b343-49f3-b59c-2d97cbbe7b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>text</th>\n",
       "      <th>readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A little less than a decade ago, hockey fans w...</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The writers of the HBO series The Sopranos too...</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Despite claims from the TV news outlet to offe...</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>After receiving 'subpar' service and experienc...</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48849</th>\n",
       "      <td>4</td>\n",
       "      <td>The ruling Kuomintang (KMT) has claimed owners...</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48850</th>\n",
       "      <td>4</td>\n",
       "      <td>The Taipei city government has encouraged the ...</td>\n",
       "      <td>13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48851</th>\n",
       "      <td>4</td>\n",
       "      <td>President Ma Ying-jeou said Friday that a park...</td>\n",
       "      <td>16.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48852</th>\n",
       "      <td>4</td>\n",
       "      <td>The families of the four people who were kille...</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48853</th>\n",
       "      <td>4</td>\n",
       "      <td>The Ministry of Finance will make public on Sa...</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48854 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       classification                                               text  \\\n",
       "0                   1  A little less than a decade ago, hockey fans w...   \n",
       "1                   1  The writers of the HBO series The Sopranos too...   \n",
       "2                   1  Despite claims from the TV news outlet to offe...   \n",
       "3                   1  After receiving 'subpar' service and experienc...   \n",
       "4                   1  After watching his beloved Seattle Mariners pr...   \n",
       "...               ...                                                ...   \n",
       "48849               4  The ruling Kuomintang (KMT) has claimed owners...   \n",
       "48850               4  The Taipei city government has encouraged the ...   \n",
       "48851               4  President Ma Ying-jeou said Friday that a park...   \n",
       "48852               4  The families of the four people who were kille...   \n",
       "48853               4  The Ministry of Finance will make public on Sa...   \n",
       "\n",
       "       readability  \n",
       "0              9.1  \n",
       "1             12.8  \n",
       "2             11.4  \n",
       "3             11.1  \n",
       "4             12.2  \n",
       "...            ...  \n",
       "48849         10.6  \n",
       "48850         13.9  \n",
       "48851         16.3  \n",
       "48852          9.4  \n",
       "48853          7.5  \n",
       "\n",
       "[48854 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Readablility\n",
    "import textstat\n",
    "\n",
    "def calculate_readbility_score(sentence):    \n",
    "    # Flesch-Kincaid Grade Level\n",
    "    return textstat.flesch_kincaid_grade(sentence)\n",
    "\n",
    "new_df = process_and_add_column(df=df, process_func=calculate_readbility_score, input_col_name=TEXT_FEATURE_NAME, new_col_name=\"readability\")\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2824bff7-4d0a-456a-b229-8bf34ab386ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>text</th>\n",
       "      <th>readability</th>\n",
       "      <th>word count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A little less than a decade ago, hockey fans w...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The writers of the HBO series The Sopranos too...</td>\n",
       "      <td>12.8</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Despite claims from the TV news outlet to offe...</td>\n",
       "      <td>11.4</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>After receiving 'subpar' service and experienc...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
       "      <td>12.2</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48849</th>\n",
       "      <td>4</td>\n",
       "      <td>The ruling Kuomintang (KMT) has claimed owners...</td>\n",
       "      <td>10.6</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48850</th>\n",
       "      <td>4</td>\n",
       "      <td>The Taipei city government has encouraged the ...</td>\n",
       "      <td>13.9</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48851</th>\n",
       "      <td>4</td>\n",
       "      <td>President Ma Ying-jeou said Friday that a park...</td>\n",
       "      <td>16.3</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48852</th>\n",
       "      <td>4</td>\n",
       "      <td>The families of the four people who were kille...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48853</th>\n",
       "      <td>4</td>\n",
       "      <td>The Ministry of Finance will make public on Sa...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48854 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       classification                                               text  \\\n",
       "0                   1  A little less than a decade ago, hockey fans w...   \n",
       "1                   1  The writers of the HBO series The Sopranos too...   \n",
       "2                   1  Despite claims from the TV news outlet to offe...   \n",
       "3                   1  After receiving 'subpar' service and experienc...   \n",
       "4                   1  After watching his beloved Seattle Mariners pr...   \n",
       "...               ...                                                ...   \n",
       "48849               4  The ruling Kuomintang (KMT) has claimed owners...   \n",
       "48850               4  The Taipei city government has encouraged the ...   \n",
       "48851               4  President Ma Ying-jeou said Friday that a park...   \n",
       "48852               4  The families of the four people who were kille...   \n",
       "48853               4  The Ministry of Finance will make public on Sa...   \n",
       "\n",
       "       readability  word count  \n",
       "0              9.1         163  \n",
       "1             12.8         135  \n",
       "2             11.4         808  \n",
       "3             11.1         811  \n",
       "4             12.2         207  \n",
       "...            ...         ...  \n",
       "48849         10.6         703  \n",
       "48850         13.9         305  \n",
       "48851         16.3         453  \n",
       "48852          9.4         269  \n",
       "48853          7.5         133  \n",
       "\n",
       "[48854 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Token Count\n",
    "import textstat\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def count_tokens(sentence):\n",
    "    return len(word_tokenize(sentence))\n",
    "\n",
    "new_df = process_and_add_column(df=df, process_func=count_tokens, input_col_name=TEXT_FEATURE_NAME, new_col_name=\"word count\")\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ea8a9d7-adc6-4542-9a4f-5a98bd3a2adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>text</th>\n",
       "      <th>readability</th>\n",
       "      <th>word count</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A little less than a decade ago, hockey fans w...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>163</td>\n",
       "      <td>0.193722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The writers of the HBO series The Sopranos too...</td>\n",
       "      <td>12.8</td>\n",
       "      <td>135</td>\n",
       "      <td>0.087879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Despite claims from the TV news outlet to offe...</td>\n",
       "      <td>11.4</td>\n",
       "      <td>808</td>\n",
       "      <td>0.075720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>After receiving 'subpar' service and experienc...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>811</td>\n",
       "      <td>0.121929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
       "      <td>12.2</td>\n",
       "      <td>207</td>\n",
       "      <td>0.157817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48849</th>\n",
       "      <td>4</td>\n",
       "      <td>The ruling Kuomintang (KMT) has claimed owners...</td>\n",
       "      <td>10.6</td>\n",
       "      <td>703</td>\n",
       "      <td>-0.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48850</th>\n",
       "      <td>4</td>\n",
       "      <td>The Taipei city government has encouraged the ...</td>\n",
       "      <td>13.9</td>\n",
       "      <td>305</td>\n",
       "      <td>0.077396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48851</th>\n",
       "      <td>4</td>\n",
       "      <td>President Ma Ying-jeou said Friday that a park...</td>\n",
       "      <td>16.3</td>\n",
       "      <td>453</td>\n",
       "      <td>0.074430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48852</th>\n",
       "      <td>4</td>\n",
       "      <td>The families of the four people who were kille...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>269</td>\n",
       "      <td>-0.073457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48853</th>\n",
       "      <td>4</td>\n",
       "      <td>The Ministry of Finance will make public on Sa...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>133</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48854 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       classification                                               text  \\\n",
       "0                   1  A little less than a decade ago, hockey fans w...   \n",
       "1                   1  The writers of the HBO series The Sopranos too...   \n",
       "2                   1  Despite claims from the TV news outlet to offe...   \n",
       "3                   1  After receiving 'subpar' service and experienc...   \n",
       "4                   1  After watching his beloved Seattle Mariners pr...   \n",
       "...               ...                                                ...   \n",
       "48849               4  The ruling Kuomintang (KMT) has claimed owners...   \n",
       "48850               4  The Taipei city government has encouraged the ...   \n",
       "48851               4  President Ma Ying-jeou said Friday that a park...   \n",
       "48852               4  The families of the four people who were kille...   \n",
       "48853               4  The Ministry of Finance will make public on Sa...   \n",
       "\n",
       "       readability  word count  polarity  \n",
       "0              9.1         163  0.193722  \n",
       "1             12.8         135  0.087879  \n",
       "2             11.4         808  0.075720  \n",
       "3             11.1         811  0.121929  \n",
       "4             12.2         207  0.157817  \n",
       "...            ...         ...       ...  \n",
       "48849         10.6         703 -0.038000  \n",
       "48850         13.9         305  0.077396  \n",
       "48851         16.3         453  0.074430  \n",
       "48852          9.4         269 -0.073457  \n",
       "48853          7.5         133  0.050000  \n",
       "\n",
       "[48854 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Polarity\n",
    "from textblob import TextBlob\n",
    "def get_polarity(sentence):\n",
    "    return TextBlob(sentence).sentiment.polarity\n",
    "\n",
    "new_df = process_and_add_column(df=new_df, process_func=get_polarity, input_col_name=TEXT_FEATURE_NAME, new_col_name=\"polarity\")\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "915efcdf-51ac-4105-9fba-02e36d573085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>text</th>\n",
       "      <th>readability</th>\n",
       "      <th>word count</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A little less than a decade ago, hockey fans w...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>163</td>\n",
       "      <td>0.193722</td>\n",
       "      <td>0.487111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The writers of the HBO series The Sopranos too...</td>\n",
       "      <td>12.8</td>\n",
       "      <td>135</td>\n",
       "      <td>0.087879</td>\n",
       "      <td>0.327652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Despite claims from the TV news outlet to offe...</td>\n",
       "      <td>11.4</td>\n",
       "      <td>808</td>\n",
       "      <td>0.075720</td>\n",
       "      <td>0.432300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>After receiving 'subpar' service and experienc...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>811</td>\n",
       "      <td>0.121929</td>\n",
       "      <td>0.433119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
       "      <td>12.2</td>\n",
       "      <td>207</td>\n",
       "      <td>0.157817</td>\n",
       "      <td>0.585132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48849</th>\n",
       "      <td>4</td>\n",
       "      <td>The ruling Kuomintang (KMT) has claimed owners...</td>\n",
       "      <td>10.6</td>\n",
       "      <td>703</td>\n",
       "      <td>-0.038000</td>\n",
       "      <td>0.379000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48850</th>\n",
       "      <td>4</td>\n",
       "      <td>The Taipei city government has encouraged the ...</td>\n",
       "      <td>13.9</td>\n",
       "      <td>305</td>\n",
       "      <td>0.077396</td>\n",
       "      <td>0.480677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48851</th>\n",
       "      <td>4</td>\n",
       "      <td>President Ma Ying-jeou said Friday that a park...</td>\n",
       "      <td>16.3</td>\n",
       "      <td>453</td>\n",
       "      <td>0.074430</td>\n",
       "      <td>0.181448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48852</th>\n",
       "      <td>4</td>\n",
       "      <td>The families of the four people who were kille...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>269</td>\n",
       "      <td>-0.073457</td>\n",
       "      <td>0.348457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48853</th>\n",
       "      <td>4</td>\n",
       "      <td>The Ministry of Finance will make public on Sa...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>133</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.327083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48854 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       classification                                               text  \\\n",
       "0                   1  A little less than a decade ago, hockey fans w...   \n",
       "1                   1  The writers of the HBO series The Sopranos too...   \n",
       "2                   1  Despite claims from the TV news outlet to offe...   \n",
       "3                   1  After receiving 'subpar' service and experienc...   \n",
       "4                   1  After watching his beloved Seattle Mariners pr...   \n",
       "...               ...                                                ...   \n",
       "48849               4  The ruling Kuomintang (KMT) has claimed owners...   \n",
       "48850               4  The Taipei city government has encouraged the ...   \n",
       "48851               4  President Ma Ying-jeou said Friday that a park...   \n",
       "48852               4  The families of the four people who were kille...   \n",
       "48853               4  The Ministry of Finance will make public on Sa...   \n",
       "\n",
       "       readability  word count  polarity  subjectivity  \n",
       "0              9.1         163  0.193722      0.487111  \n",
       "1             12.8         135  0.087879      0.327652  \n",
       "2             11.4         808  0.075720      0.432300  \n",
       "3             11.1         811  0.121929      0.433119  \n",
       "4             12.2         207  0.157817      0.585132  \n",
       "...            ...         ...       ...           ...  \n",
       "48849         10.6         703 -0.038000      0.379000  \n",
       "48850         13.9         305  0.077396      0.480677  \n",
       "48851         16.3         453  0.074430      0.181448  \n",
       "48852          9.4         269 -0.073457      0.348457  \n",
       "48853          7.5         133  0.050000      0.327083  \n",
       "\n",
       "[48854 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subjectivity\n",
    "from textblob import TextBlob\n",
    "def get_subjectivity(sentence):\n",
    "    return TextBlob(sentence).sentiment.subjectivity\n",
    "\n",
    "new_df = process_and_add_column(df=new_df, process_func=get_subjectivity, input_col_name=TEXT_FEATURE_NAME, new_col_name=\"subjectivity\")\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80ac4547-6cf9-4ab4-bb73-f049987423eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment this out if you don't need to overwrite / create balancedfeatures.csv file\n",
    "# Balanced features.csv file is text + all the additional feature engineering columns.\n",
    "import os\n",
    "\n",
    "OUTPUT_FOLDER = \"processed_data\"\n",
    "FILE_NAME = \"fulltrainfeatures.csv\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "file_path = os.path.join(OUTPUT_FOLDER, FILE_NAME)\n",
    "\n",
    "new_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9438d209-e099-4d60-8bd2-13ae4abb8206",
   "metadata": {},
   "source": [
    "#### Feature Engineering Analysis (raw_data/fulltrain.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7cf5c518-c032-4ef3-ad83-80e1f6ccf484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>text</th>\n",
       "      <th>readability</th>\n",
       "      <th>word count</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A little less than a decade ago, hockey fans w...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>163</td>\n",
       "      <td>0.193722</td>\n",
       "      <td>0.487111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The writers of the HBO series The Sopranos too...</td>\n",
       "      <td>12.8</td>\n",
       "      <td>135</td>\n",
       "      <td>0.087879</td>\n",
       "      <td>0.327652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Despite claims from the TV news outlet to offe...</td>\n",
       "      <td>11.4</td>\n",
       "      <td>808</td>\n",
       "      <td>0.075720</td>\n",
       "      <td>0.432300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>After receiving 'subpar' service and experienc...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>811</td>\n",
       "      <td>0.121929</td>\n",
       "      <td>0.433119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
       "      <td>12.2</td>\n",
       "      <td>207</td>\n",
       "      <td>0.157817</td>\n",
       "      <td>0.585132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48849</th>\n",
       "      <td>4</td>\n",
       "      <td>The ruling Kuomintang (KMT) has claimed owners...</td>\n",
       "      <td>10.6</td>\n",
       "      <td>703</td>\n",
       "      <td>-0.038000</td>\n",
       "      <td>0.379000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48850</th>\n",
       "      <td>4</td>\n",
       "      <td>The Taipei city government has encouraged the ...</td>\n",
       "      <td>13.9</td>\n",
       "      <td>305</td>\n",
       "      <td>0.077396</td>\n",
       "      <td>0.480677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48851</th>\n",
       "      <td>4</td>\n",
       "      <td>President Ma Ying-jeou said Friday that a park...</td>\n",
       "      <td>16.3</td>\n",
       "      <td>453</td>\n",
       "      <td>0.074430</td>\n",
       "      <td>0.181448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48852</th>\n",
       "      <td>4</td>\n",
       "      <td>The families of the four people who were kille...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>269</td>\n",
       "      <td>-0.073457</td>\n",
       "      <td>0.348457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48853</th>\n",
       "      <td>4</td>\n",
       "      <td>The Ministry of Finance will make public on Sa...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>133</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.327083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48854 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       classification                                               text  \\\n",
       "0                   1  A little less than a decade ago, hockey fans w...   \n",
       "1                   1  The writers of the HBO series The Sopranos too...   \n",
       "2                   1  Despite claims from the TV news outlet to offe...   \n",
       "3                   1  After receiving 'subpar' service and experienc...   \n",
       "4                   1  After watching his beloved Seattle Mariners pr...   \n",
       "...               ...                                                ...   \n",
       "48849               4  The ruling Kuomintang (KMT) has claimed owners...   \n",
       "48850               4  The Taipei city government has encouraged the ...   \n",
       "48851               4  President Ma Ying-jeou said Friday that a park...   \n",
       "48852               4  The families of the four people who were kille...   \n",
       "48853               4  The Ministry of Finance will make public on Sa...   \n",
       "\n",
       "       readability  word count  polarity  subjectivity  \n",
       "0              9.1         163  0.193722      0.487111  \n",
       "1             12.8         135  0.087879      0.327652  \n",
       "2             11.4         808  0.075720      0.432300  \n",
       "3             11.1         811  0.121929      0.433119  \n",
       "4             12.2         207  0.157817      0.585132  \n",
       "...            ...         ...       ...           ...  \n",
       "48849         10.6         703 -0.038000      0.379000  \n",
       "48850         13.9         305  0.077396      0.480677  \n",
       "48851         16.3         453  0.074430      0.181448  \n",
       "48852          9.4         269 -0.073457      0.348457  \n",
       "48853          7.5         133  0.050000      0.327083  \n",
       "\n",
       "[48854 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "OUTPUT_FOLDER = \"processed_data\"\n",
    "FILE_NAME = \"fulltrainfeatures.csv\"\n",
    "file_path = os.path.join(OUTPUT_FOLDER, FILE_NAME)\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"File {file_path} does not exists!\")\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "207f875f-fddc-41cf-bfe5-10fc7b426822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>readability_median</th>\n",
       "      <th>readability_&lt;lambda_0&gt;</th>\n",
       "      <th>readability_&lt;lambda_1&gt;</th>\n",
       "      <th>readability_min</th>\n",
       "      <th>readability_max</th>\n",
       "      <th>readability_mean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>14.1</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>63.7</td>\n",
       "      <td>11.953478</td>\n",
       "      <td>Satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.2</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>47.9</td>\n",
       "      <td>8.587093</td>\n",
       "      <td>Hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8.6</td>\n",
       "      <td>12.3</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>53.3</td>\n",
       "      <td>10.556452</td>\n",
       "      <td>Propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>12.7</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>194.8</td>\n",
       "      <td>10.654297</td>\n",
       "      <td>Reliable News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classification  readability_median  readability_<lambda_0>  \\\n",
       "0               1                11.5                     9.2   \n",
       "1               2                 8.5                     7.2   \n",
       "2               3                10.4                     8.6   \n",
       "3               4                10.7                     8.6   \n",
       "\n",
       "   readability_<lambda_1>  readability_min  readability_max  readability_mean  \\\n",
       "0                    14.1             -1.2             63.7         11.953478   \n",
       "1                     9.8              2.1             47.9          8.587093   \n",
       "2                    12.3             -3.1             53.3         10.556452   \n",
       "3                    12.7             -3.1            194.8         10.654297   \n",
       "\n",
       "           label  \n",
       "0         Satire  \n",
       "1           Hoax  \n",
       "2     Propaganda  \n",
       "3  Reliable News  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df = calculate_summary_statistics_by_classifier(df, CLASSIFICATION_NAME, \"readability\")\n",
    "mean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7160f2b3-9500-4386-b1dd-db53747b0a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>word count_median</th>\n",
       "      <th>word count_&lt;lambda_0&gt;</th>\n",
       "      <th>word count_&lt;lambda_1&gt;</th>\n",
       "      <th>word count_min</th>\n",
       "      <th>word count_max</th>\n",
       "      <th>word count_mean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>184.0</td>\n",
       "      <td>139.00</td>\n",
       "      <td>615.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2465</td>\n",
       "      <td>338.721364</td>\n",
       "      <td>Satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>207.0</td>\n",
       "      <td>162.00</td>\n",
       "      <td>259.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2654</td>\n",
       "      <td>216.720542</td>\n",
       "      <td>Hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>765.0</td>\n",
       "      <td>285.25</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>2</td>\n",
       "      <td>131926</td>\n",
       "      <td>1018.812759</td>\n",
       "      <td>Propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>389.0</td>\n",
       "      <td>219.00</td>\n",
       "      <td>705.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5215</td>\n",
       "      <td>506.043422</td>\n",
       "      <td>Reliable News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classification  word count_median  word count_<lambda_0>  \\\n",
       "0               1              184.0                 139.00   \n",
       "1               2              207.0                 162.00   \n",
       "2               3              765.0                 285.25   \n",
       "3               4              389.0                 219.00   \n",
       "\n",
       "   word count_<lambda_1>  word count_min  word count_max  word count_mean  \\\n",
       "0                  615.0               2            2465       338.721364   \n",
       "1                  259.0               2            2654       216.720542   \n",
       "2                 1341.0               2          131926      1018.812759   \n",
       "3                  705.0               2            5215       506.043422   \n",
       "\n",
       "           label  \n",
       "0         Satire  \n",
       "1           Hoax  \n",
       "2     Propaganda  \n",
       "3  Reliable News  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df = calculate_summary_statistics_by_classifier(df, CLASSIFICATION_NAME, \"word count\")\n",
    "mean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6be17fd-741f-40fa-9606-00a632c611da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>polarity_median</th>\n",
       "      <th>polarity_&lt;lambda_0&gt;</th>\n",
       "      <th>polarity_&lt;lambda_1&gt;</th>\n",
       "      <th>polarity_min</th>\n",
       "      <th>polarity_max</th>\n",
       "      <th>polarity_mean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.085707</td>\n",
       "      <td>0.014813</td>\n",
       "      <td>0.152381</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.084869</td>\n",
       "      <td>Satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.044395</td>\n",
       "      <td>-0.032763</td>\n",
       "      <td>0.121446</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.043747</td>\n",
       "      <td>Hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.064151</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.105504</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.064741</td>\n",
       "      <td>Propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.016441</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.070584</td>\n",
       "      <td>Reliable News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classification  polarity_median  polarity_<lambda_0>  polarity_<lambda_1>  \\\n",
       "0               1         0.085707             0.014813             0.152381   \n",
       "1               2         0.044395            -0.032763             0.121446   \n",
       "2               3         0.064151             0.013889             0.105504   \n",
       "3               4         0.070389             0.016441             0.122222   \n",
       "\n",
       "   polarity_min  polarity_max  polarity_mean          label  \n",
       "0          -0.8           1.0       0.084869         Satire  \n",
       "1          -1.0           1.0       0.043747           Hoax  \n",
       "2          -1.0           1.0       0.064741     Propaganda  \n",
       "3          -0.8           0.8       0.070584  Reliable News  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df = calculate_summary_statistics_by_classifier(df, CLASSIFICATION_NAME, \"polarity\")\n",
    "mean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8416bac5-e3f9-4916-a7c7-a0ef3aa239e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>subjectivity_median</th>\n",
       "      <th>subjectivity_&lt;lambda_0&gt;</th>\n",
       "      <th>subjectivity_&lt;lambda_1&gt;</th>\n",
       "      <th>subjectivity_min</th>\n",
       "      <th>subjectivity_max</th>\n",
       "      <th>subjectivity_mean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.476816</td>\n",
       "      <td>0.416818</td>\n",
       "      <td>0.533346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.473221</td>\n",
       "      <td>Satire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.447006</td>\n",
       "      <td>0.377219</td>\n",
       "      <td>0.517568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.448432</td>\n",
       "      <td>Hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.431018</td>\n",
       "      <td>0.374292</td>\n",
       "      <td>0.476456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.399500</td>\n",
       "      <td>Propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.384991</td>\n",
       "      <td>0.316008</td>\n",
       "      <td>0.443910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.372629</td>\n",
       "      <td>Reliable News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classification  subjectivity_median  subjectivity_<lambda_0>  \\\n",
       "0               1             0.476816                 0.416818   \n",
       "1               2             0.447006                 0.377219   \n",
       "2               3             0.431018                 0.374292   \n",
       "3               4             0.384991                 0.316008   \n",
       "\n",
       "   subjectivity_<lambda_1>  subjectivity_min  subjectivity_max  \\\n",
       "0                 0.533346               0.0               1.0   \n",
       "1                 0.517568               0.0               1.0   \n",
       "2                 0.476456               0.0               1.0   \n",
       "3                 0.443910               0.0               1.0   \n",
       "\n",
       "   subjectivity_mean          label  \n",
       "0           0.473221         Satire  \n",
       "1           0.448432           Hoax  \n",
       "2           0.399500     Propaganda  \n",
       "3           0.372629  Reliable News  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df = calculate_summary_statistics_by_classifier(df, CLASSIFICATION_NAME, \"subjectivity\")\n",
    "mean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219d2eaf-d02d-43e8-b295-a361b2ecada7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d37877-303a-494d-b7b0-b53f7b2c22d7",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5f1ebe-18d2-4264-8658-90e5c8e9b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textstat\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "\n",
    "def normalize(data):\n",
    "    return (data-data.mean())/data.std()\n",
    "\n",
    "def count_tokens(sentence):\n",
    "    return len(word_tokenize(sentence))\n",
    "\n",
    "def get_polarity(sentence):\n",
    "    return TextBlob(sentence).sentiment.polarity\n",
    "\n",
    "def get_subjectivity(sentence):\n",
    "    return TextBlob(sentence).sentiment.subjectivity\n",
    "\n",
    "def add_features(data):\n",
    "    \n",
    "    # Add features\n",
    "    token_count = data.apply(lambda x: count_tokens(x))\n",
    "    readability = data.apply(lambda x: textstat.flesch_reading_ease(x))\n",
    "    polarity = data.apply(lambda x: get_polarity(x))\n",
    "    subjectivity = data.apply(lambda x: get_subjectivity(x))\n",
    "    \n",
    "    # Normalize features\n",
    "    token_count = normalize(token_count)\n",
    "    readability = normalize(readability)\n",
    "    polarity = normalize(polarity)\n",
    "    subjectivity = normalize(subjectivity)\n",
    "    \n",
    "    return pd.concat([token_count, readability, polarity, subjectivity], axis=1)\n",
    "\n",
    "\n",
    "train = pd.read_csv('balancedtest.csv', header=None)\n",
    "\n",
    "x_train = train[train.columns[1]]\n",
    "y_train = train[train.columns[0]]\n",
    "\n",
    "train_features = add_features(x_train)\n",
    "\n",
    "print(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91081f05-7bb2-45c8-a463-9fc9f52c9a9f",
   "metadata": {},
   "source": [
    "## Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74e3a22a-8b3d-4d6d-adf2-8a06687a143a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>classification</th>\n",
       "      <th>readability</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>polarity</th>\n",
       "      <th>word count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>little le than decade ago hockey fan were ble...</td>\n",
       "      <td>1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.487111</td>\n",
       "      <td>0.193722</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The writer of the HBO series The Sopranos took...</td>\n",
       "      <td>1</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.327652</td>\n",
       "      <td>0.087879</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Despite claim from the TV news outlet to offer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.432300</td>\n",
       "      <td>0.075720</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>After receiving subpar service and experiencin...</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.433119</td>\n",
       "      <td>0.121929</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.585132</td>\n",
       "      <td>0.157817</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48849</th>\n",
       "      <td>The ruling Kuomintang KMT ha claimed ownership...</td>\n",
       "      <td>4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.379000</td>\n",
       "      <td>-0.038000</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48850</th>\n",
       "      <td>The Taipei city government ha encouraged the r...</td>\n",
       "      <td>4</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.480677</td>\n",
       "      <td>0.077396</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48851</th>\n",
       "      <td>President Ma Ying-jeou said Friday that park b...</td>\n",
       "      <td>4</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.181448</td>\n",
       "      <td>0.074430</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48852</th>\n",
       "      <td>The family of the four people who were killed ...</td>\n",
       "      <td>4</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.348457</td>\n",
       "      <td>-0.073457</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48853</th>\n",
       "      <td>The Ministry of Finance will make public on Sa...</td>\n",
       "      <td>4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.327083</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48854 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  classification  \\\n",
       "0       little le than decade ago hockey fan were ble...               1   \n",
       "1      The writer of the HBO series The Sopranos took...               1   \n",
       "2      Despite claim from the TV news outlet to offer...               1   \n",
       "3      After receiving subpar service and experiencin...               1   \n",
       "4      After watching his beloved Seattle Mariners pr...               1   \n",
       "...                                                  ...             ...   \n",
       "48849  The ruling Kuomintang KMT ha claimed ownership...               4   \n",
       "48850  The Taipei city government ha encouraged the r...               4   \n",
       "48851  President Ma Ying-jeou said Friday that park b...               4   \n",
       "48852  The family of the four people who were killed ...               4   \n",
       "48853  The Ministry of Finance will make public on Sa...               4   \n",
       "\n",
       "       readability  subjectivity  polarity  word count  \n",
       "0              9.1      0.487111  0.193722         163  \n",
       "1             12.8      0.327652  0.087879         135  \n",
       "2             11.4      0.432300  0.075720         808  \n",
       "3             11.1      0.433119  0.121929         811  \n",
       "4             12.2      0.585132  0.157817         207  \n",
       "...            ...           ...       ...         ...  \n",
       "48849         10.6      0.379000 -0.038000         703  \n",
       "48850         13.9      0.480677  0.077396         305  \n",
       "48851         16.3      0.181448  0.074430         453  \n",
       "48852          9.4      0.348457 -0.073457         269  \n",
       "48853          7.5      0.327083  0.050000         133  \n",
       "\n",
       "[48854 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "OUTPUT_FOLDER = \"preprocessed_data\"\n",
    "FILE_NAME = \"preprocessed_fe_train.csv\"\n",
    "file_path = os.path.join(OUTPUT_FOLDER, FILE_NAME)\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"File {file_path} does not exists!\")\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11f29d89-8ec1-4da7-ac2a-09a52edebd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                    text  readability  \\\n",
       " 0       little le than decade ago hockey fan were ble...          9.1   \n",
       " 1      The writer of the HBO series The Sopranos took...         12.8   \n",
       " 2      Despite claim from the TV news outlet to offer...         11.4   \n",
       " 3      After receiving subpar service and experiencin...         11.1   \n",
       " 4      After watching his beloved Seattle Mariners pr...         12.2   \n",
       " ...                                                  ...          ...   \n",
       " 48849  The ruling Kuomintang KMT ha claimed ownership...         10.6   \n",
       " 48850  The Taipei city government ha encouraged the r...         13.9   \n",
       " 48851  President Ma Ying-jeou said Friday that park b...         16.3   \n",
       " 48852  The family of the four people who were killed ...          9.4   \n",
       " 48853  The Ministry of Finance will make public on Sa...          7.5   \n",
       " \n",
       "        subjectivity  polarity  word count  \n",
       " 0          0.487111  0.193722         163  \n",
       " 1          0.327652  0.087879         135  \n",
       " 2          0.432300  0.075720         808  \n",
       " 3          0.433119  0.121929         811  \n",
       " 4          0.585132  0.157817         207  \n",
       " ...             ...       ...         ...  \n",
       " 48849      0.379000 -0.038000         703  \n",
       " 48850      0.480677  0.077396         305  \n",
       " 48851      0.181448  0.074430         453  \n",
       " 48852      0.348457 -0.073457         269  \n",
       " 48853      0.327083  0.050000         133  \n",
       " \n",
       " [48854 rows x 5 columns],\n",
       " 0        1\n",
       " 1        1\n",
       " 2        1\n",
       " 3        1\n",
       " 4        1\n",
       "         ..\n",
       " 48849    4\n",
       " 48850    4\n",
       " 48851    4\n",
       " 48852    4\n",
       " 48853    4\n",
       " Name: classification, Length: 48854, dtype: int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=[CLASSIFICATION_NAME])\n",
    "y = df[CLASSIFICATION_NAME]\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ada1293-7ce1-43fb-a37f-b4e815a0014d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000 people</th>\n",
       "      <th>10</th>\n",
       "      <th>10 000</th>\n",
       "      <th>10 year</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>your</th>\n",
       "      <th>your own</th>\n",
       "      <th>youre</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youve</th>\n",
       "      <th>yuan</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033184</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48849</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.02597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48850</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48851</th>\n",
       "      <td>0.025499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48852</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48853</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48854 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            000  000 people        10  10 000  10 year  100        11   12  \\\n",
       "0      0.000000         0.0  0.000000     0.0      0.0  0.0  0.000000  0.0   \n",
       "1      0.000000         0.0  0.067415     0.0      0.0  0.0  0.000000  0.0   \n",
       "2      0.000000         0.0  0.156228     0.0      0.0  0.0  0.052157  0.0   \n",
       "3      0.000000         0.0  0.048272     0.0      0.0  0.0  0.000000  0.0   \n",
       "4      0.000000         0.0  0.000000     0.0      0.0  0.0  0.000000  0.0   \n",
       "...         ...         ...       ...     ...      ...  ...       ...  ...   \n",
       "48849  0.000000         0.0  0.000000     0.0      0.0  0.0  0.000000  0.0   \n",
       "48850  0.000000         0.0  0.000000     0.0      0.0  0.0  0.000000  0.0   \n",
       "48851  0.025499         0.0  0.025998     0.0      0.0  0.0  0.000000  0.0   \n",
       "48852  0.000000         0.0  0.000000     0.0      0.0  0.0  0.000000  0.0   \n",
       "48853  0.000000         0.0  0.052109     0.0      0.0  0.0  0.000000  0.0   \n",
       "\n",
       "             13       14  ...  your  your own  youre  yourself     youth  \\\n",
       "0      0.000000  0.00000  ...   0.0       0.0    0.0       0.0  0.000000   \n",
       "1      0.000000  0.00000  ...   0.0       0.0    0.0       0.0  0.000000   \n",
       "2      0.000000  0.00000  ...   0.0       0.0    0.0       0.0  0.000000   \n",
       "3      0.033184  0.00000  ...   0.0       0.0    0.0       0.0  0.000000   \n",
       "4      0.000000  0.00000  ...   0.0       0.0    0.0       0.0  0.000000   \n",
       "...         ...      ...  ...   ...       ...    ...       ...       ...   \n",
       "48849  0.000000  0.02597  ...   0.0       0.0    0.0       0.0  0.000000   \n",
       "48850  0.000000  0.00000  ...   0.0       0.0    0.0       0.0  0.000000   \n",
       "48851  0.000000  0.00000  ...   0.0       0.0    0.0       0.0  0.046798   \n",
       "48852  0.000000  0.00000  ...   0.0       0.0    0.0       0.0  0.000000   \n",
       "48853  0.000000  0.00000  ...   0.0       0.0    0.0       0.0  0.000000   \n",
       "\n",
       "       youtube  youve  yuan  zero  zone  \n",
       "0          0.0    0.0   0.0   0.0   0.0  \n",
       "1          0.0    0.0   0.0   0.0   0.0  \n",
       "2          0.0    0.0   0.0   0.0   0.0  \n",
       "3          0.0    0.0   0.0   0.0   0.0  \n",
       "4          0.0    0.0   0.0   0.0   0.0  \n",
       "...        ...    ...   ...   ...   ...  \n",
       "48849      0.0    0.0   0.0   0.0   0.0  \n",
       "48850      0.0    0.0   0.0   0.0   0.0  \n",
       "48851      0.0    0.0   0.0   0.0   0.0  \n",
       "48852      0.0    0.0   0.0   0.0   0.0  \n",
       "48853      0.0    0.0   0.0   0.0   0.0  \n",
       "\n",
       "[48854 rows x 5000 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: remove this once feature engineering is up\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "max_features = 5000\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=max_features, ngram_range=(1,3))\n",
    "# Solution to np.str_ to convert invalid document characters to string from this post:\n",
    "# https://stackoverflow.com/questions/39303912/tfidfvectorizer-in-scikit-learn-valueerror-np-nan-is-an-invalid-document\n",
    "tfidf_matrix = vectorizer.fit_transform(X[TEXT_FEATURE_NAME].apply(lambda x: np.str_(x)))\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea9eaca2-ceeb-467b-b63a-9025103e6c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000 people</th>\n",
       "      <th>10</th>\n",
       "      <th>10 000</th>\n",
       "      <th>10 year</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youve</th>\n",
       "      <th>yuan</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>readability_</th>\n",
       "      <th>word count_</th>\n",
       "      <th>subjectivity_</th>\n",
       "      <th>polarity_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>163</td>\n",
       "      <td>0.487111</td>\n",
       "      <td>0.193722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>135</td>\n",
       "      <td>0.327652</td>\n",
       "      <td>0.087879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>808</td>\n",
       "      <td>0.432300</td>\n",
       "      <td>0.075720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033184</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>811</td>\n",
       "      <td>0.433119</td>\n",
       "      <td>0.121929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>207</td>\n",
       "      <td>0.585132</td>\n",
       "      <td>0.157817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48849</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.02597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>703</td>\n",
       "      <td>0.379000</td>\n",
       "      <td>-0.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48850</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>305</td>\n",
       "      <td>0.480677</td>\n",
       "      <td>0.077396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48851</th>\n",
       "      <td>0.025499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>453</td>\n",
       "      <td>0.181448</td>\n",
       "      <td>0.074430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48852</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>269</td>\n",
       "      <td>0.348457</td>\n",
       "      <td>-0.073457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48853</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>133</td>\n",
       "      <td>0.327083</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48854 rows × 5004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            000  000 people        10  10 000  10 year  100        11   12  \\\n",
       "0      0.000000         0.0  0.000000     0.0      0.0  0.0  0.000000  0.0   \n",
       "1      0.000000         0.0  0.067415     0.0      0.0  0.0  0.000000  0.0   \n",
       "2      0.000000         0.0  0.156228     0.0      0.0  0.0  0.052157  0.0   \n",
       "3      0.000000         0.0  0.048272     0.0      0.0  0.0  0.000000  0.0   \n",
       "4      0.000000         0.0  0.000000     0.0      0.0  0.0  0.000000  0.0   \n",
       "...         ...         ...       ...     ...      ...  ...       ...  ...   \n",
       "48849  0.000000         0.0  0.000000     0.0      0.0  0.0  0.000000  0.0   \n",
       "48850  0.000000         0.0  0.000000     0.0      0.0  0.0  0.000000  0.0   \n",
       "48851  0.025499         0.0  0.025998     0.0      0.0  0.0  0.000000  0.0   \n",
       "48852  0.000000         0.0  0.000000     0.0      0.0  0.0  0.000000  0.0   \n",
       "48853  0.000000         0.0  0.052109     0.0      0.0  0.0  0.000000  0.0   \n",
       "\n",
       "             13       14  ...     youth  youtube  youve  yuan  zero  zone  \\\n",
       "0      0.000000  0.00000  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "1      0.000000  0.00000  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "2      0.000000  0.00000  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "3      0.033184  0.00000  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "4      0.000000  0.00000  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "...         ...      ...  ...       ...      ...    ...   ...   ...   ...   \n",
       "48849  0.000000  0.02597  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "48850  0.000000  0.00000  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "48851  0.000000  0.00000  ...  0.046798      0.0    0.0   0.0   0.0   0.0   \n",
       "48852  0.000000  0.00000  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "48853  0.000000  0.00000  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "\n",
       "       readability_  word count_  subjectivity_  polarity_  \n",
       "0               9.1          163       0.487111   0.193722  \n",
       "1              12.8          135       0.327652   0.087879  \n",
       "2              11.4          808       0.432300   0.075720  \n",
       "3              11.1          811       0.433119   0.121929  \n",
       "4              12.2          207       0.585132   0.157817  \n",
       "...             ...          ...            ...        ...  \n",
       "48849          10.6          703       0.379000  -0.038000  \n",
       "48850          13.9          305       0.480677   0.077396  \n",
       "48851          16.3          453       0.181448   0.074430  \n",
       "48852           9.4          269       0.348457  -0.073457  \n",
       "48853           7.5          133       0.327083   0.050000  \n",
       "\n",
       "[48854 rows x 5004 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add in all the feature engineering features (active choice to put '_' at back of features not from vectorizer to differentiate)\n",
    "tfidf_df['readability_'] = X['readability']\n",
    "tfidf_df['word count_'] = X['word count']\n",
    "tfidf_df['subjectivity_'] = X['subjectivity']\n",
    "tfidf_df['polarity_'] = X['polarity']\n",
    "\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b657cc1f-554e-455b-adca-f345f557b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Squeeze to between 0 and 1\n",
    "def normalise(col):\n",
    "    minimum = col.min()\n",
    "    maximum = col.max()\n",
    "    return (col - minimum) / (maximum - minimum)\n",
    "\n",
    "normalised_df = tfidf_df.apply(normalise)\n",
    "normalised_df.to_csv(os.path.join(\"preprocessed_data\", \"normalised_fulltrain.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12234a80-2034-4f8b-a724-e0b2cfb30d4c",
   "metadata": {},
   "source": [
    "##  Reading the Data (No need care about above if we already have normalised data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "051b4d33-0e7b-442d-882f-bbb3e06f86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "normalised_df = pd.read_csv('preprocessed_data/normalised_fulltrain.csv')\n",
    "X = normalised_df.drop(columns=[CLASSIFICATION_NAME])\n",
    "y = normalised_df[CLASSIFICATION_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55b08d8d-74e8-424c-b6aa-7b80f1abf87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000 people</th>\n",
       "      <th>10</th>\n",
       "      <th>10 000</th>\n",
       "      <th>10 year</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youve</th>\n",
       "      <th>yuan</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>readability_</th>\n",
       "      <th>word count_</th>\n",
       "      <th>subjectivity_</th>\n",
       "      <th>polarity_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061647</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.487111</td>\n",
       "      <td>0.596861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080344</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.327652</td>\n",
       "      <td>0.543939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073269</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>0.432300</td>\n",
       "      <td>0.537860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071753</td>\n",
       "      <td>0.006132</td>\n",
       "      <td>0.433119</td>\n",
       "      <td>0.560964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077312</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.585132</td>\n",
       "      <td>0.578909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48849</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.051973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069227</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.379000</td>\n",
       "      <td>0.481000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48850</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085902</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.480677</td>\n",
       "      <td>0.538698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48851</th>\n",
       "      <td>0.037581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.181448</td>\n",
       "      <td>0.537215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48852</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063163</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.348457</td>\n",
       "      <td>0.463272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48853</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053562</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.327083</td>\n",
       "      <td>0.525000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48854 rows × 5004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            000  000 people        10  10 000  10 year  100        11   12  \\\n",
       "0      0.000000         0.0  0.000000     0.0      0.0  0.0  0.000000  0.0   \n",
       "1      0.000000         0.0  0.097965     0.0      0.0  0.0  0.000000  0.0   \n",
       "2      0.000000         0.0  0.227022     0.0      0.0  0.0  0.061645  0.0   \n",
       "3      0.000000         0.0  0.070147     0.0      0.0  0.0  0.000000  0.0   \n",
       "4      0.000000         0.0  0.000000     0.0      0.0  0.0  0.000000  0.0   \n",
       "...         ...         ...       ...     ...      ...  ...       ...  ...   \n",
       "48849  0.000000         0.0  0.000000     0.0      0.0  0.0  0.000000  0.0   \n",
       "48850  0.000000         0.0  0.000000     0.0      0.0  0.0  0.000000  0.0   \n",
       "48851  0.037581         0.0  0.037779     0.0      0.0  0.0  0.000000  0.0   \n",
       "48852  0.000000         0.0  0.000000     0.0      0.0  0.0  0.000000  0.0   \n",
       "48853  0.000000         0.0  0.075722     0.0      0.0  0.0  0.000000  0.0   \n",
       "\n",
       "            13        14  ...     youth  youtube  youve  yuan  zero  zone  \\\n",
       "0      0.00000  0.000000  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "1      0.00000  0.000000  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "2      0.00000  0.000000  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "3      0.08108  0.000000  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "4      0.00000  0.000000  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "...        ...       ...  ...       ...      ...    ...   ...   ...   ...   \n",
       "48849  0.00000  0.051973  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "48850  0.00000  0.000000  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "48851  0.00000  0.000000  ...  0.047842      0.0    0.0   0.0   0.0   0.0   \n",
       "48852  0.00000  0.000000  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "48853  0.00000  0.000000  ...  0.000000      0.0    0.0   0.0   0.0   0.0   \n",
       "\n",
       "       readability_  word count_  subjectivity_  polarity_  \n",
       "0          0.061647     0.001220       0.487111   0.596861  \n",
       "1          0.080344     0.001008       0.327652   0.543939  \n",
       "2          0.073269     0.006110       0.432300   0.537860  \n",
       "3          0.071753     0.006132       0.433119   0.560964  \n",
       "4          0.077312     0.001554       0.585132   0.578909  \n",
       "...             ...          ...            ...        ...  \n",
       "48849      0.069227     0.005314       0.379000   0.481000  \n",
       "48850      0.085902     0.002297       0.480677   0.538698  \n",
       "48851      0.098029     0.003419       0.181448   0.537215  \n",
       "48852      0.063163     0.002024       0.348457   0.463272  \n",
       "48853      0.053562     0.000993       0.327083   0.525000  \n",
       "\n",
       "[48854 rows x 5004 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10799508-ce3d-4356-9984-2191bb02bb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "48849    4\n",
       "48850    4\n",
       "48851    4\n",
       "48852    4\n",
       "48853    4\n",
       "Name: classification, Length: 48854, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc08365-4dc1-443c-af24-b0439fda9f21",
   "metadata": {},
   "source": [
    "## Settings for train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ad85677-cb12-40ac-ad2d-06a66df162fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Settings\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "## Note: Change this to fit the algorithm below\n",
    "# X are the features\n",
    "X = X\n",
    "# y are the outputs\n",
    "y = y\n",
    "# test_size is the size of the test (0 < test_size < 1)\n",
    "test_size = 0.2\n",
    "# seed for random split\n",
    "seed = 40\n",
    "## End of Note\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb7c17-5286-4121-869e-2f597d956fcd",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caecce32-df65-4ec5-96b6-eeb4e5755d4e",
   "metadata": {},
   "source": [
    "#### Running Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "362bc350-c65f-4b53-91de-c616d5c9beef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9713437723876778\n",
      "Confusion Matrix:\n",
      "[[2679    9   45   42]\n",
      " [  15 1369   37    7]\n",
      " [  13   10 3514   20]\n",
      " [  41    3   38 1929]]\n",
      "F1 Macro Score: 0.9702647156328439\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "evaluation_metrics = [(\"Accuracy\", accuracy_score), (\"Confusion Matrix\", confusion_matrix)]\n",
    "\n",
    "for evaluation_metric_name, evaluation_metric_func in evaluation_metrics:\n",
    "    print(f\"{evaluation_metric_name}:\\n{evaluation_metric_func(y_test, y_pred)}\")\n",
    "print(f\"F1 Macro Score: {f1_score(y_test, y_pred, average='macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e0b47b-303f-4aca-b43b-a3d24598453b",
   "metadata": {},
   "source": [
    "#### Saving Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "396a2df9-dfd6-4e9c-b1d3-53d4608b2e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLEASE REMEMBER TO RUN THE \"CONSTANTS\" CELL (USES classifier_mapping)\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "OUTPUT_FOLDER = \"results\"\n",
    "model_name = \"logistic_regression\"\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "    \n",
    "for i in range(4):\n",
    "    class_name = classifier_mapping[i + 1]\n",
    "    filename = f\"{model_name}_{class_name}.csv\"\n",
    "    coefficients = model.coef_[i]\n",
    "    coefficients_df = pd.DataFrame({'Features': X_train.columns, 'Coefficient': coefficients})\n",
    "    coefficients_df['coefficient magnitude'] = abs(coefficients_df['Coefficient'])\n",
    "    coefficients_df = coefficients_df.sort_values(by='coefficient magnitude', ascending=False)\n",
    "    coefficients_df.to_csv(os.path.join(OUTPUT_FOLDER, filename), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084fc2e7-aeee-4080-8680-23588b8647c9",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6348dc32-3156-4985-9b21-914c7a137440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9035922628185447\n",
      "Confusion Matrix:\n",
      "[[2518   20   85  152]\n",
      " [  65 1315   37   11]\n",
      " [  97   53 3336   71]\n",
      " [ 270    6   75 1660]]\n",
      "F1 Macro Score: 0.900712396685067\n"
     ]
    }
   ],
   "source": [
    "# For Feature engineering peeps, X cannot contain negative values for multinomial NB. \n",
    "# Must either clip or shift and scale the value to get rid of negative values!\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "evaluation_metrics = [(\"Accuracy\", accuracy_score), (\"Confusion Matrix\", confusion_matrix)]\n",
    "\n",
    "for evaluation_metric_name, evaluation_metric_func in evaluation_metrics:\n",
    "    print(f\"{evaluation_metric_name}:\\n{evaluation_metric_func(y_test, y_pred)}\")\n",
    "print(f\"F1 Macro Score: {f1_score(y_test, y_pred, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2477cc00-d55e-4e93-a076-a09ee2e55284",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = \"results\"\n",
    "model_name = \"multinomial_nb\"\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "    \n",
    "for i, class_label in enumerate(model.classes_):\n",
    "    class_name = classifier_mapping[i + 1]\n",
    "    filename = f\"{model_name}_{class_name}.csv\"\n",
    "    feature_log_probabilities = model.feature_log_prob_[i]\n",
    "    feature_importances_df = pd.DataFrame({'Features': X_train.columns, 'Log Probability': feature_log_probabilities})\n",
    "    feature_importances_df['probability magnitude'] = abs(feature_importances_df['Log Probability'])\n",
    "    feature_importances_df = feature_importances_df.sort_values(by='probability magnitude', ascending=False)\n",
    "    feature_importances_df.to_csv(os.path.join(OUTPUT_FOLDER, filename), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536fbc6a-422f-4b00-88c1-05b735d66593",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a002416e-7a0c-4262-a948-984db058960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(image_height, image_width, num_channels)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dense(units=num_classes, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b71d99-4b32-4f2e-afdf-9ebecf2b3b70",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db360e1-233c-40ea-ba87-ebb8fc6d06e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "\n",
    "X_train_array = X_train.to_numpy()\n",
    "X_test_array = X_test.to_numpy()\n",
    "y_train_array = y_train.to_numpy()\n",
    "y_test_array = y_test.to_numpy()\n",
    "\n",
    "num_samples, num_features = X_train_array.shape\n",
    "timesteps = 1  # You may need to adjust this depending on your data\n",
    "\n",
    "X_train_reshaped = X_train_array.reshape(num_samples, timesteps, num_features)\n",
    "X_test_reshaped = X_test_array.reshape(X_test_array.shape[0], timesteps, X_test_array.shape[1])\n",
    "\n",
    "\n",
    "# create model here\n",
    "model = tf.keras.Sequential([\n",
    "    SimpleRNN(units=32, input_shape=(timesteps, num_features)),\n",
    "    Dense(units=4)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32)\n",
    "loss, accuracy = model.evaluate(X_test_reshaped, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e134bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_reshaped)\n",
    "y_labels = np.argmax(y_pred, axis=1) + 1\n",
    "\n",
    "evaluation_metrics = [(\"Accuracy\", accuracy_score), (\"Confusion Matrix\", confusion_matrix)]\n",
    "\n",
    "for evaluation_metric_name, evaluation_metric_func in evaluation_metrics:\n",
    "    print(f\"{evaluation_metric_name}:\\n{evaluation_metric_func(y_test, y_labels)}\")\n",
    "f1_score(y_test, y_labels, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbbe374-2fca-4b13-adb8-c97d2208518e",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527cfa48-a6bf-4390-8fea-4139b44ead4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your pandas DataFrame with a column named 'text' containing the sentences\n",
    "# and a column named 'label_column' containing the labels\n",
    "# Example DataFrame:\n",
    "# df = pd.DataFrame({'text': [\"This is sentence 1.\", \"Another sentence.\", \"Yet another sentence.\"],\n",
    "#                    'label_column': [0, 1, 1]})\n",
    "\n",
    "X = df[1].values\n",
    "y = df[0].values\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Padding\n",
    "max_sequence_length = 100 # max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# Convert to Numeric\n",
    "X = padded_sequences\n",
    "y = y\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build LSTM Model\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 100  # Adjust as needed\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "model.add(LSTM(units=128, implementation=2))  # Disable CuDNN\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define a data generator\n",
    "def data_generator(X, y, batch_size):\n",
    "    num_samples = X.shape[0]\n",
    "    while True:\n",
    "        indices = np.random.permutation(np.arange(num_samples))\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_indices = indices[i:i+batch_size]\n",
    "            yield X[batch_indices], y[batch_indices]\n",
    "\n",
    "# Train Model with Data Generator\n",
    "batch_size = 32\n",
    "steps_per_epoch = len(X_train) // batch_size\n",
    "train_generator = data_generator(X_train, y_train, batch_size)\n",
    "\n",
    "# Train Model with Generator\n",
    "model.fit(train_generator, epochs=10, steps_per_epoch=steps_per_epoch, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred = model.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"F1 score (macro):\", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35037039-7f05-47bb-8cbd-fd68d0679300",
   "metadata": {},
   "source": [
    "## Evaluation [unable to see other feature names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d11451-f66d-44db-974d-f63a16aa34af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(model, X_train)\n",
    "shap_values = explainer.shap_values(X_test[50:100])\n",
    "shap.summary_plot(shap_values, X_test[50:100], max_display=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
