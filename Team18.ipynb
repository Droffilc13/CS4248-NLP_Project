{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c3d2f91-1f6f-4b8a-be8c-eb673e74ef6d",
   "metadata": {},
   "source": [
    "# CS4248 NLP Project Team 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e0af41-f2e7-40e9-850a-a08f76908f4e",
   "metadata": {},
   "source": [
    "## Installing necessary libraries\n",
    "\n",
    "*Note*: Put libraries that need to be installed with `!pip install LIBRARY` so that we can ensure consistency in packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acd8a95b-3cc9-48bc-b669-479e3a06b97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from scikit-learn) (3.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp311-cp311-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.16.1-cp311-cp311-win_amd64.whl (377.0 MB)\n",
      "                                              0.0/377.0 MB ? eta -:--:--\n",
      "                                             0.5/377.0 MB 14.2 MB/s eta 0:00:27\n",
      "                                             1.2/377.0 MB 15.2 MB/s eta 0:00:25\n",
      "                                             2.1/377.0 MB 16.8 MB/s eta 0:00:23\n",
      "                                             3.2/377.0 MB 18.8 MB/s eta 0:00:20\n",
      "                                             4.3/377.0 MB 19.4 MB/s eta 0:00:20\n",
      "                                             4.9/377.0 MB 20.7 MB/s eta 0:00:18\n",
      "                                             5.4/377.0 MB 17.2 MB/s eta 0:00:22\n",
      "                                             6.7/377.0 MB 18.6 MB/s eta 0:00:20\n",
      "                                             7.6/377.0 MB 19.5 MB/s eta 0:00:19\n",
      "                                             9.4/377.0 MB 20.7 MB/s eta 0:00:18\n",
      "     -                                      11.0/377.0 MB 23.4 MB/s eta 0:00:16\n",
      "     -                                      12.8/377.0 MB 25.2 MB/s eta 0:00:15\n",
      "     -                                      14.4/377.0 MB 27.3 MB/s eta 0:00:14\n",
      "     -                                      15.8/377.0 MB 32.7 MB/s eta 0:00:12\n",
      "     -                                      17.5/377.0 MB 34.6 MB/s eta 0:00:11\n",
      "     -                                      19.6/377.0 MB 36.4 MB/s eta 0:00:10\n",
      "     --                                     21.5/377.0 MB 38.6 MB/s eta 0:00:10\n",
      "     --                                     23.5/377.0 MB 38.5 MB/s eta 0:00:10\n",
      "     --                                     25.7/377.0 MB 40.9 MB/s eta 0:00:09\n",
      "     --                                     27.8/377.0 MB 43.5 MB/s eta 0:00:09\n",
      "     --                                     29.7/377.0 MB 43.5 MB/s eta 0:00:08\n",
      "     ---                                    31.7/377.0 MB 43.5 MB/s eta 0:00:08\n",
      "     ---                                    33.9/377.0 MB 43.7 MB/s eta 0:00:08\n",
      "     ---                                    35.9/377.0 MB 43.7 MB/s eta 0:00:08\n",
      "     ---                                    37.6/377.0 MB 46.7 MB/s eta 0:00:08\n",
      "     ---                                    39.5/377.0 MB 43.7 MB/s eta 0:00:08\n",
      "     ----                                   42.0/377.0 MB 43.7 MB/s eta 0:00:08\n",
      "     ----                                   43.7/377.0 MB 43.7 MB/s eta 0:00:08\n",
      "     ----                                   46.0/377.0 MB 43.7 MB/s eta 0:00:08\n",
      "     ----                                   46.1/377.0 MB 43.5 MB/s eta 0:00:08\n",
      "     ----                                   46.1/377.0 MB 43.5 MB/s eta 0:00:08\n",
      "     ----                                   46.1/377.0 MB 43.5 MB/s eta 0:00:08\n",
      "     ----                                   46.1/377.0 MB 43.5 MB/s eta 0:00:08\n",
      "     ----                                   47.3/377.0 MB 23.4 MB/s eta 0:00:15\n",
      "     ----                                   49.1/377.0 MB 23.4 MB/s eta 0:00:15\n",
      "     -----                                  51.9/377.0 MB 24.2 MB/s eta 0:00:14\n",
      "     -----                                  53.4/377.0 MB 23.4 MB/s eta 0:00:14\n",
      "     -----                                  55.2/377.0 MB 23.4 MB/s eta 0:00:14\n",
      "     -----                                  57.5/377.0 MB 43.5 MB/s eta 0:00:08\n",
      "     ------                                 59.9/377.0 MB 46.7 MB/s eta 0:00:07\n",
      "     ------                                 62.0/377.0 MB 43.5 MB/s eta 0:00:08\n",
      "     ------                                 63.8/377.0 MB 46.7 MB/s eta 0:00:07\n",
      "     ------                                 65.3/377.0 MB 43.7 MB/s eta 0:00:08\n",
      "     ------                                 67.5/377.0 MB 43.7 MB/s eta 0:00:08\n",
      "     -------                                69.6/377.0 MB 40.9 MB/s eta 0:00:08\n",
      "     -------                                71.8/377.0 MB 40.9 MB/s eta 0:00:08\n",
      "     -------                                73.8/377.0 MB 40.9 MB/s eta 0:00:08\n",
      "     -------                                75.7/377.0 MB 43.5 MB/s eta 0:00:07\n",
      "     -------                                77.9/377.0 MB 46.7 MB/s eta 0:00:07\n",
      "     --------                               80.0/377.0 MB 46.7 MB/s eta 0:00:07\n",
      "     --------                               82.1/377.0 MB 43.7 MB/s eta 0:00:07\n",
      "     --------                               84.5/377.0 MB 46.7 MB/s eta 0:00:07\n",
      "     --------                               86.2/377.0 MB 43.7 MB/s eta 0:00:07\n",
      "     --------                               88.6/377.0 MB 43.7 MB/s eta 0:00:07\n",
      "     ---------                              90.3/377.0 MB 43.5 MB/s eta 0:00:07\n",
      "     ---------                              92.4/377.0 MB 43.5 MB/s eta 0:00:07\n",
      "     ---------                              93.8/377.0 MB 43.7 MB/s eta 0:00:07\n",
      "     ---------                              95.4/377.0 MB 38.6 MB/s eta 0:00:08\n",
      "     ---------                              98.1/377.0 MB 40.9 MB/s eta 0:00:07\n",
      "     ---------                              99.2/377.0 MB 36.4 MB/s eta 0:00:08\n",
      "     ---------                             101.5/377.0 MB 38.5 MB/s eta 0:00:08\n",
      "     ----------                            103.4/377.0 MB 38.5 MB/s eta 0:00:08\n",
      "     ----------                            105.2/377.0 MB 38.5 MB/s eta 0:00:08\n",
      "     ----------                            107.4/377.0 MB 38.5 MB/s eta 0:00:08\n",
      "     ----------                            109.4/377.0 MB 40.9 MB/s eta 0:00:07\n",
      "     ----------                            111.4/377.0 MB 38.5 MB/s eta 0:00:07\n",
      "     -----------                           113.3/377.0 MB 40.9 MB/s eta 0:00:07\n",
      "     -----------                           115.4/377.0 MB 40.9 MB/s eta 0:00:07\n",
      "     -----------                           117.1/377.0 MB 40.9 MB/s eta 0:00:07\n",
      "     -----------                           119.0/377.0 MB 40.9 MB/s eta 0:00:07\n",
      "     -----------                           120.5/377.0 MB 38.5 MB/s eta 0:00:07\n",
      "     ------------                          122.8/377.0 MB 40.9 MB/s eta 0:00:07\n",
      "     ------------                          124.9/377.0 MB 40.9 MB/s eta 0:00:07\n",
      "     ------------                          126.6/377.0 MB 40.9 MB/s eta 0:00:07\n",
      "     ------------                          129.3/377.0 MB 46.9 MB/s eta 0:00:06\n",
      "     ------------                          131.1/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "     ------------                          132.2/377.0 MB 43.7 MB/s eta 0:00:06\n",
      "     -------------                         135.1/377.0 MB 43.7 MB/s eta 0:00:06\n",
      "     -------------                         136.0/377.0 MB 40.9 MB/s eta 0:00:06\n",
      "     -------------                         136.9/377.0 MB 38.5 MB/s eta 0:00:07\n",
      "     -------------                         139.3/377.0 MB 36.3 MB/s eta 0:00:07\n",
      "     -------------                         141.8/377.0 MB 38.6 MB/s eta 0:00:07\n",
      "     --------------                        143.7/377.0 MB 38.6 MB/s eta 0:00:07\n",
      "     --------------                        146.6/377.0 MB 46.7 MB/s eta 0:00:05\n",
      "     --------------                        148.7/377.0 MB 50.4 MB/s eta 0:00:05\n",
      "     --------------                        151.2/377.0 MB 50.4 MB/s eta 0:00:05\n",
      "     ---------------                       153.4/377.0 MB 50.4 MB/s eta 0:00:05\n",
      "     ---------------                       155.6/377.0 MB 50.4 MB/s eta 0:00:05\n",
      "     ---------------                       156.7/377.0 MB 50.4 MB/s eta 0:00:05\n",
      "     ---------------                       158.6/377.0 MB 43.7 MB/s eta 0:00:05\n",
      "     ---------------                       161.0/377.0 MB 43.7 MB/s eta 0:00:05\n",
      "     ---------------                       162.6/377.0 MB 40.9 MB/s eta 0:00:06\n",
      "     ----------------                      164.0/377.0 MB 40.9 MB/s eta 0:00:06\n",
      "     ----------------                      165.9/377.0 MB 36.4 MB/s eta 0:00:06\n",
      "     ----------------                      168.1/377.0 MB 38.5 MB/s eta 0:00:06\n",
      "     ----------------                      170.1/377.0 MB 38.6 MB/s eta 0:00:06\n",
      "     ----------------                      172.6/377.0 MB 43.5 MB/s eta 0:00:05\n",
      "     -----------------                     173.8/377.0 MB 40.9 MB/s eta 0:00:05\n",
      "     -----------------                     175.7/377.0 MB 40.9 MB/s eta 0:00:05\n",
      "     -----------------                     177.8/377.0 MB 38.5 MB/s eta 0:00:06\n",
      "     -----------------                     179.6/377.0 MB 40.9 MB/s eta 0:00:05\n",
      "     -----------------                     181.1/377.0 MB 36.3 MB/s eta 0:00:06\n",
      "     -----------------                     182.6/377.0 MB 36.4 MB/s eta 0:00:06\n",
      "     ------------------                    184.5/377.0 MB 36.4 MB/s eta 0:00:06\n",
      "     ------------------                    186.7/377.0 MB 38.6 MB/s eta 0:00:05\n",
      "     ------------------                    188.9/377.0 MB 40.9 MB/s eta 0:00:05\n",
      "     ------------------                    191.4/377.0 MB 46.9 MB/s eta 0:00:04\n",
      "     ------------------                    193.2/377.0 MB 50.4 MB/s eta 0:00:04\n",
      "     -------------------                   194.6/377.0 MB 43.7 MB/s eta 0:00:05\n",
      "     -------------------                   196.7/377.0 MB 43.7 MB/s eta 0:00:05\n",
      "     -------------------                   197.1/377.0 MB 43.5 MB/s eta 0:00:05\n",
      "     -------------------                   197.1/377.0 MB 43.5 MB/s eta 0:00:05\n",
      "     -------------------                   197.1/377.0 MB 43.5 MB/s eta 0:00:05\n",
      "     -------------------                   199.1/377.0 MB 28.5 MB/s eta 0:00:07\n",
      "     -------------------                   201.5/377.0 MB 27.3 MB/s eta 0:00:07\n",
      "     -------------------                   203.6/377.0 MB 28.4 MB/s eta 0:00:07\n",
      "     --------------------                  204.8/377.0 MB 28.5 MB/s eta 0:00:07\n",
      "     --------------------                  207.2/377.0 MB 28.5 MB/s eta 0:00:06\n",
      "     --------------------                  209.3/377.0 MB 43.5 MB/s eta 0:00:04\n",
      "     --------------------                  211.4/377.0 MB 43.5 MB/s eta 0:00:04\n",
      "     --------------------                  213.7/377.0 MB 43.5 MB/s eta 0:00:04\n",
      "     ---------------------                 215.8/377.0 MB 50.4 MB/s eta 0:00:04\n",
      "     ---------------------                 217.7/377.0 MB 46.9 MB/s eta 0:00:04\n",
      "     ---------------------                 220.1/377.0 MB 46.7 MB/s eta 0:00:04\n",
      "     ---------------------                 222.1/377.0 MB 46.7 MB/s eta 0:00:04\n",
      "     ----------------------                224.9/377.0 MB 46.7 MB/s eta 0:00:04\n",
      "     ----------------------                226.9/377.0 MB 46.7 MB/s eta 0:00:04\n",
      "     ----------------------                229.4/377.0 MB 50.4 MB/s eta 0:00:03\n",
      "     ----------------------                231.3/377.0 MB 46.7 MB/s eta 0:00:04\n",
      "     ----------------------                233.7/377.0 MB 46.9 MB/s eta 0:00:04\n",
      "     -----------------------               235.9/377.0 MB 50.4 MB/s eta 0:00:03\n",
      "     -----------------------               238.5/377.0 MB 50.4 MB/s eta 0:00:03\n",
      "     -----------------------               241.0/377.0 MB 46.7 MB/s eta 0:00:03\n",
      "     -----------------------               243.0/377.0 MB 50.4 MB/s eta 0:00:03\n",
      "     ------------------------              245.1/377.0 MB 50.4 MB/s eta 0:00:03\n",
      "     ------------------------              247.2/377.0 MB 50.4 MB/s eta 0:00:03\n",
      "     ------------------------              249.4/377.0 MB 50.4 MB/s eta 0:00:03\n",
      "     ------------------------              251.7/377.0 MB 46.7 MB/s eta 0:00:03\n",
      "     ------------------------              253.2/377.0 MB 40.9 MB/s eta 0:00:04\n",
      "     -------------------------             256.1/377.0 MB 46.7 MB/s eta 0:00:03\n",
      "     -------------------------             257.8/377.0 MB 46.9 MB/s eta 0:00:03\n",
      "     -------------------------             260.1/377.0 MB 46.9 MB/s eta 0:00:03\n",
      "     -------------------------             262.6/377.0 MB 46.7 MB/s eta 0:00:03\n",
      "     -------------------------             264.3/377.0 MB 46.7 MB/s eta 0:00:03\n",
      "     --------------------------            266.5/377.0 MB 46.7 MB/s eta 0:00:03\n",
      "     --------------------------            268.6/377.0 MB 46.7 MB/s eta 0:00:03\n",
      "     --------------------------            271.0/377.0 MB 46.7 MB/s eta 0:00:03\n",
      "     --------------------------            273.2/377.0 MB 46.7 MB/s eta 0:00:03\n",
      "     --------------------------            275.0/377.0 MB 46.9 MB/s eta 0:00:03\n",
      "     ---------------------------           277.3/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "     ---------------------------           279.9/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "     ---------------------------           282.2/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "     ---------------------------           284.0/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "     ----------------------------          285.6/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "     ----------------------------          287.8/377.0 MB 46.7 MB/s eta 0:00:02\n",
      "     ----------------------------          289.9/377.0 MB 43.5 MB/s eta 0:00:03\n",
      "     ----------------------------          292.0/377.0 MB 43.7 MB/s eta 0:00:02\n",
      "     ----------------------------          293.6/377.0 MB 40.9 MB/s eta 0:00:03\n",
      "     ----------------------------          293.6/377.0 MB 40.9 MB/s eta 0:00:03\n",
      "     -----------------------------         295.6/377.0 MB 34.4 MB/s eta 0:00:03\n",
      "     -----------------------------         297.1/377.0 MB 32.7 MB/s eta 0:00:03\n",
      "     -----------------------------         298.9/377.0 MB 32.7 MB/s eta 0:00:03\n",
      "     -----------------------------         300.7/377.0 MB 32.7 MB/s eta 0:00:03\n",
      "     -----------------------------         302.5/377.0 MB 34.4 MB/s eta 0:00:03\n",
      "     -----------------------------         304.2/377.0 MB 38.6 MB/s eta 0:00:02\n",
      "     ------------------------------        305.7/377.0 MB 38.5 MB/s eta 0:00:02\n",
      "     ------------------------------        307.6/377.0 MB 40.9 MB/s eta 0:00:02\n",
      "     ------------------------------        310.3/377.0 MB 43.7 MB/s eta 0:00:02\n",
      "     ------------------------------        312.4/377.0 MB 43.7 MB/s eta 0:00:02\n",
      "     ------------------------------        313.9/377.0 MB 43.7 MB/s eta 0:00:02\n",
      "     -------------------------------       316.4/377.0 MB 43.5 MB/s eta 0:00:02\n",
      "     -------------------------------       318.1/377.0 MB 46.7 MB/s eta 0:00:02\n",
      "     -------------------------------       320.0/377.0 MB 40.9 MB/s eta 0:00:02\n",
      "     -------------------------------       321.4/377.0 MB 38.6 MB/s eta 0:00:02\n",
      "     -------------------------------       322.4/377.0 MB 34.4 MB/s eta 0:00:02\n",
      "     -------------------------------       324.9/377.0 MB 36.4 MB/s eta 0:00:02\n",
      "     --------------------------------      326.5/377.0 MB 38.6 MB/s eta 0:00:02\n",
      "     --------------------------------      329.1/377.0 MB 38.5 MB/s eta 0:00:02\n",
      "     --------------------------------      330.6/377.0 MB 40.9 MB/s eta 0:00:02\n",
      "     --------------------------------      332.5/377.0 MB 43.7 MB/s eta 0:00:02\n",
      "     --------------------------------      334.9/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     --------------------------------      335.8/377.0 MB 46.7 MB/s eta 0:00:01\n",
      "     ---------------------------------     338.8/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ---------------------------------     340.1/377.0 MB 40.9 MB/s eta 0:00:01\n",
      "     ---------------------------------     342.6/377.0 MB 43.7 MB/s eta 0:00:01\n",
      "     ---------------------------------     344.4/377.0 MB 46.7 MB/s eta 0:00:01\n",
      "     ----------------------------------    346.4/377.0 MB 46.7 MB/s eta 0:00:01\n",
      "     ----------------------------------    348.8/377.0 MB 43.7 MB/s eta 0:00:01\n",
      "     ----------------------------------    349.6/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ----------------------------------    352.2/377.0 MB 40.9 MB/s eta 0:00:01\n",
      "     ----------------------------------    353.7/377.0 MB 38.5 MB/s eta 0:00:01\n",
      "     ----------------------------------    354.9/377.0 MB 40.9 MB/s eta 0:00:01\n",
      "     ----------------------------------    356.1/377.0 MB 36.4 MB/s eta 0:00:01\n",
      "     -----------------------------------   357.3/377.0 MB 32.8 MB/s eta 0:00:01\n",
      "     -----------------------------------   359.0/377.0 MB 32.8 MB/s eta 0:00:01\n",
      "     -----------------------------------   360.7/377.0 MB 32.7 MB/s eta 0:00:01\n",
      "     -----------------------------------   363.5/377.0 MB 36.4 MB/s eta 0:00:01\n",
      "     -----------------------------------   365.4/377.0 MB 36.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  367.5/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  369.5/377.0 MB 46.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  371.9/377.0 MB 46.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  373.9/377.0 MB 43.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  376.0/377.0 MB 43.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  377.0/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 377.0/377.0 MB 5.5 MB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "                                              0.0/133.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 133.7/133.7 kB ? eta 0:00:00\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading h5py-3.10.0-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "                                              0.0/2.7 MB ? eta -:--:--\n",
      "     ----------------                         1.1/2.7 MB 33.9 MB/s eta 0:00:01\n",
      "     -----------------------------------      2.4/2.7 MB 29.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.7/2.7 MB 24.2 MB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "                                              0.0/26.4 MB ? eta -:--:--\n",
      "     -                                        1.2/26.4 MB 76.2 MB/s eta 0:00:01\n",
      "     ----                                     3.0/26.4 MB 37.8 MB/s eta 0:00:01\n",
      "     -----                                    3.5/26.4 MB 27.7 MB/s eta 0:00:01\n",
      "     -------                                  5.2/26.4 MB 33.3 MB/s eta 0:00:01\n",
      "     ---------                                6.1/26.4 MB 27.8 MB/s eta 0:00:01\n",
      "     ------------                             8.1/26.4 MB 30.3 MB/s eta 0:00:01\n",
      "     --------------                          10.1/26.4 MB 32.2 MB/s eta 0:00:01\n",
      "     ----------------                        11.2/26.4 MB 29.7 MB/s eta 0:00:01\n",
      "     --------------------                    14.1/26.4 MB 36.3 MB/s eta 0:00:01\n",
      "     -----------------------                 16.2/26.4 MB 43.7 MB/s eta 0:00:01\n",
      "     --------------------------              18.1/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "     ----------------------------            19.5/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "     --------------------------------        22.0/26.4 MB 46.7 MB/s eta 0:00:01\n",
      "     -----------------------------------     24.2/26.4 MB 43.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  26.2/26.4 MB 43.5 MB/s eta 0:00:01\n",
      "     --------------------------------------  26.4/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  26.4/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "     --------------------------------------- 26.4/26.4 MB 29.7 MB/s eta 0:00:00\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading ml_dtypes-0.3.2-cp311-cp311-win_amd64.whl (127 kB)\n",
      "                                              0.0/127.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 127.7/127.7 kB ? eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "                                              0.0/413.4 kB ? eta -:--:--\n",
      "     ------------------------------------- 413.4/413.4 kB 26.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.11.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading grpcio-1.62.1-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "                                              0.0/3.8 MB ? eta -:--:--\n",
      "     ------                                   0.6/3.8 MB 18.2 MB/s eta 0:00:01\n",
      "     ----------------                         1.6/3.8 MB 17.0 MB/s eta 0:00:01\n",
      "     --------------------------------------   3.6/3.8 MB 29.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.8/3.8 MB 27.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.8/3.8 MB 27.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.8/3.8 MB 27.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.8/3.8 MB 27.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.8/3.8 MB 11.0 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "                                              0.0/5.5 MB ? eta -:--:--\n",
      "     -------                                  1.0/5.5 MB 22.0 MB/s eta 0:00:01\n",
      "     ----------------------                   3.1/5.5 MB 32.6 MB/s eta 0:00:01\n",
      "     -----------------------------------      4.9/5.5 MB 34.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.5/5.5 MB 35.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.5/5.5 MB 27.0 MB/s eta 0:00:00\n",
      "Collecting keras>=3.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading keras-3.2.0-py3-none-any.whl (1.1 MB)\n",
      "                                              0.0/1.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.1/1.1 MB 34.4 MB/s eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "                                              0.0/65.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.8/65.8 kB ? eta 0:00:00\n",
      "Collecting rich (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "                                              0.0/240.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 240.7/240.7 kB ? eta 0:00:00\n",
      "Collecting namex (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading optree-0.11.0-cp311-cp311-win_amd64.whl (245 kB)\n",
      "                                              0.0/245.0 kB ? eta -:--:--\n",
      "     ------------------------------------- 245.0/245.0 kB 14.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "                                              0.0/105.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 105.4/105.4 kB ? eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading werkzeug-3.0.2-py3-none-any.whl (226 kB)\n",
      "                                              0.0/226.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 226.8/226.8 kB 6.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "                                              0.0/87.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 87.5/87.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\documents\\github\\cs4248-nlp_project\\nlpenv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, markdown, h5py, grpcio, google-pasta, gast, absl-py, tensorboard, markdown-it-py, astunparse, rich, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.5.4 google-pasta-0.2.0 grpcio-1.62.1 h5py-3.10.0 keras-3.2.0 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.7 opt-einsum-3.3.0 optree-0.11.0 protobuf-4.25.3 rich-13.7.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-intel-2.16.1 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0 werkzeug-3.0.2 wheel-0.43.0 wrapt-1.16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install tensorflow\n",
    "!pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa46d2bc-9a4b-47b1-829e-c7db818d13c0",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "783a07b5-7b7b-4b4d-a60c-88bd9518a7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A little less than a decade ago, hockey fans w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The writers of the HBO series The Sopranos too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Despite claims from the TV news outlet to offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>After receiving 'subpar' service and experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  1  A little less than a decade ago, hockey fans w...\n",
       "1  1  The writers of the HBO series The Sopranos too...\n",
       "2  1  Despite claims from the TV news outlet to offe...\n",
       "3  1  After receiving 'subpar' service and experienc...\n",
       "4  1  After watching his beloved Seattle Mariners pr..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_FILEPATH = \"raw_data/fulltrain.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_FILEPATH, header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b9bb89a-3e1d-434f-8904-69d9220a637c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    A little less than a decade ago, hockey fans w...\n",
      "1    The writers of the HBO series The Sopranos too...\n",
      "2    Despite claims from the TV news outlet to offe...\n",
      "3    After receiving 'subpar' service and experienc...\n",
      "4    After watching his beloved Seattle Mariners pr...\n",
      "Name: 1, dtype: object\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df[1]\n",
    "y = df[0]\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92acb502-671c-441a-b82c-29a5edd337e4",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48003e8a-7bfb-42fa-a0d2-e5244930d200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "value_counts = df[0].value_counts()\n",
    "value_counts.plot(kind='bar')\n",
    "plt.xlabel('Classification')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Breakdown of Text Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219d2eaf-d02d-43e8-b295-a361b2ecada7",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d37877-303a-494d-b7b0-b53f7b2c22d7",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91081f05-7bb2-45c8-a463-9fc9f52c9a9f",
   "metadata": {},
   "source": [
    "## Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ada1293-7ce1-43fb-a37f-b4e815a0014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "max_features = 10000\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "tfidf_matrix = vectorizer.fit_transform(X)\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc08365-4dc1-443c-af24-b0439fda9f21",
   "metadata": {},
   "source": [
    "## Settings for train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ad85677-cb12-40ac-ad2d-06a66df162fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Settings\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "## Note: Change this to fit the algorithm below\n",
    "# X are the features\n",
    "X = tfidf_df\n",
    "# y are the outputs\n",
    "y = y\n",
    "# test_size is the size of the test (0 < test_size < 1)\n",
    "test_size = 0.2\n",
    "# seed for random split\n",
    "seed = 40\n",
    "## End of Note\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb7c17-5286-4121-869e-2f597d956fcd",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "362bc350-c65f-4b53-91de-c616d5c9beef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9639750281445093\n",
      "Confusion Matrix:\n",
      "[[2689   11   46   29]\n",
      " [  17 1349   54    8]\n",
      " [  30   27 3482   18]\n",
      " [  58    3   51 1899]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "evaluation_metrics = [(\"Accuracy\", accuracy_score), (\"Confusion Matrix\", confusion_matrix)]\n",
    "\n",
    "for evaluation_metric_name, evaluation_metric_func in evaluation_metrics:\n",
    "    print(f\"{evaluation_metric_name}:\\n{evaluation_metric_func(y_test, y_pred)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "396a2df9-dfd6-4e9c-b1d3-53d4608b2e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9639750281445093\n",
      "Confusion Matrix:\n",
      "[[2689   11   46   29]\n",
      " [  17 1349   54    8]\n",
      " [  30   27 3482   18]\n",
      " [  58    3   51 1899]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9623921309659836"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics = [(\"Accuracy\", accuracy_score), (\"Confusion Matrix\", confusion_matrix)]\n",
    "\n",
    "for evaluation_metric_name, evaluation_metric_func in evaluation_metrics:\n",
    "    print(f\"{evaluation_metric_name}:\\n{evaluation_metric_func(y_test, y_pred)}\")\n",
    "f1_score(y_test, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536fbc6a-422f-4b00-88c1-05b735d66593",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a002416e-7a0c-4262-a948-984db058960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(image_height, image_width, num_channels)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dense(units=num_classes, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b71d99-4b32-4f2e-afdf-9ebecf2b3b70",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db360e1-233c-40ea-ba87-ebb8fc6d06e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Documents\\GitHub\\CS4248-NLP_Project\\nlpenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3350 - loss: 1.4576\n",
      "Epoch 2/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2070 - loss: 0.2639\n",
      "Epoch 3/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1962 - loss: 0.2381\n",
      "Epoch 4/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1897 - loss: 0.2283\n",
      "Epoch 5/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2031 - loss: 0.2168\n",
      "Epoch 6/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2010 - loss: 0.2082\n",
      "Epoch 7/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1786 - loss: 0.1989\n",
      "Epoch 8/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1721 - loss: 0.1856\n",
      "Epoch 9/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1758 - loss: 0.1759\n",
      "Epoch 10/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1926 - loss: 0.1644\n",
      "Epoch 11/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1974 - loss: 0.1543\n",
      "Epoch 12/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1993 - loss: 0.1460\n",
      "Epoch 13/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2023 - loss: 0.1361\n",
      "Epoch 14/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2053 - loss: 0.1307\n",
      "Epoch 15/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2058 - loss: 0.1229\n",
      "Epoch 16/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2109 - loss: 0.1176\n",
      "Epoch 17/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2097 - loss: 0.1083\n",
      "Epoch 18/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2113 - loss: 0.1026\n",
      "Epoch 19/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2215 - loss: 0.0953\n",
      "Epoch 20/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2131 - loss: 0.0870\n",
      "Epoch 21/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2106 - loss: 0.0834\n",
      "Epoch 22/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2070 - loss: 0.0771\n",
      "Epoch 23/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2127 - loss: 0.0719\n",
      "Epoch 24/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2143 - loss: 0.0664\n",
      "Epoch 25/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2147 - loss: 0.0624\n",
      "Epoch 26/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2226 - loss: 0.0564\n",
      "Epoch 27/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2272 - loss: 0.0517\n",
      "Epoch 28/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2285 - loss: 0.0470\n",
      "Epoch 29/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2372 - loss: 0.0441\n",
      "Epoch 30/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2313 - loss: 0.0406\n",
      "Epoch 31/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2326 - loss: 0.0366\n",
      "Epoch 32/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2351 - loss: 0.0334\n",
      "Epoch 33/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2213 - loss: 0.0303\n",
      "Epoch 34/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2214 - loss: 0.0280\n",
      "Epoch 35/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2170 - loss: 0.0246\n",
      "Epoch 36/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2117 - loss: 0.0225\n",
      "Epoch 37/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2128 - loss: 0.0203\n",
      "Epoch 38/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2087 - loss: 0.0186\n",
      "Epoch 39/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2071 - loss: 0.0163\n",
      "Epoch 40/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2087 - loss: 0.0146\n",
      "Epoch 41/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2050 - loss: 0.0128\n",
      "Epoch 42/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2003 - loss: 0.0114\n",
      "Epoch 43/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1998 - loss: 0.0103\n",
      "Epoch 44/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1959 - loss: 0.0090\n",
      "Epoch 45/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1957 - loss: 0.0082\n",
      "Epoch 46/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1913 - loss: 0.0071\n",
      "Epoch 47/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1931 - loss: 0.0065\n",
      "Epoch 48/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1875 - loss: 0.0058\n",
      "Epoch 49/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1822 - loss: 0.0054\n",
      "Epoch 50/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1891 - loss: 0.0049\n",
      "Epoch 51/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1865 - loss: 0.0045\n",
      "Epoch 52/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1839 - loss: 0.0039\n",
      "Epoch 53/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1844 - loss: 0.0037\n",
      "Epoch 54/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1816 - loss: 0.0036\n",
      "Epoch 55/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1875 - loss: 0.0032\n",
      "Epoch 56/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1812 - loss: 0.0031\n",
      "Epoch 57/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1855 - loss: 0.0029\n",
      "Epoch 58/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1818 - loss: 0.0029\n",
      "Epoch 59/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1881 - loss: 0.0026\n",
      "Epoch 60/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1807 - loss: 0.0026\n",
      "Epoch 61/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1867 - loss: 0.0025\n",
      "Epoch 62/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1880 - loss: 0.0022\n",
      "Epoch 63/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1859 - loss: 0.0025\n",
      "Epoch 64/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1834 - loss: 0.0021\n",
      "Epoch 65/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1884 - loss: 0.0020\n",
      "Epoch 66/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1874 - loss: 0.0021\n",
      "Epoch 67/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1889 - loss: 0.0019\n",
      "Epoch 68/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1925 - loss: 0.0019\n",
      "Epoch 69/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1845 - loss: 0.0018\n",
      "Epoch 70/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1825 - loss: 0.0018\n",
      "Epoch 71/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1868 - loss: 0.0017\n",
      "Epoch 72/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1867 - loss: 0.0017\n",
      "Epoch 73/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1949 - loss: 0.0018\n",
      "Epoch 74/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1852 - loss: 0.0017\n",
      "Epoch 75/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1884 - loss: 0.0016\n",
      "Epoch 76/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1841 - loss: 0.0016\n",
      "Epoch 77/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1859 - loss: 0.0016\n",
      "Epoch 78/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1904 - loss: 0.0015\n",
      "Epoch 79/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1906 - loss: 0.0014\n",
      "Epoch 80/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1911 - loss: 0.0016\n",
      "Epoch 81/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1893 - loss: 0.0016\n",
      "Epoch 82/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1872 - loss: 0.0015\n",
      "Epoch 83/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1866 - loss: 0.0014\n",
      "Epoch 84/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1893 - loss: 0.0015\n",
      "Epoch 85/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1856 - loss: 0.0013\n",
      "Epoch 86/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1909 - loss: 0.0015\n",
      "Epoch 87/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1922 - loss: 0.0013\n",
      "Epoch 88/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1920 - loss: 0.0013\n",
      "Epoch 89/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1864 - loss: 0.0013\n",
      "Epoch 90/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1877 - loss: 0.0014\n",
      "Epoch 91/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1872 - loss: 0.0012\n",
      "Epoch 92/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1900 - loss: 0.0012\n",
      "Epoch 93/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1865 - loss: 0.0012\n",
      "Epoch 94/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1884 - loss: 0.0012\n",
      "Epoch 95/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1858 - loss: 0.0012\n",
      "Epoch 96/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1881 - loss: 0.0014\n",
      "Epoch 97/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1864 - loss: 0.0012\n",
      "Epoch 98/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1911 - loss: 0.0013\n",
      "Epoch 99/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1836 - loss: 0.0011\n",
      "Epoch 100/100\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1856 - loss: 0.0012\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2590 - loss: 0.1958\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "\n",
    "X_train_array = X_train.to_numpy()\n",
    "X_test_array = X_test.to_numpy()\n",
    "y_train_array = y_train.to_numpy()\n",
    "y_test_array = y_test.to_numpy()\n",
    "\n",
    "num_samples, num_features = X_train_array.shape\n",
    "timesteps = 1  # You may need to adjust this depending on your data\n",
    "\n",
    "X_train_reshaped = X_train_array.reshape(num_samples, timesteps, num_features)\n",
    "X_test_reshaped = X_test_array.reshape(X_test_array.shape[0], timesteps, X_test_array.shape[1])\n",
    "\n",
    "\n",
    "# create model here\n",
    "model = tf.keras.Sequential([\n",
    "    SimpleRNN(units=32, input_shape=(timesteps, num_features)),\n",
    "    Dense(units=4)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32)\n",
    "loss, accuracy = model.evaluate(X_test_reshaped, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbbe374-2fca-4b13-adb8-c97d2208518e",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "527cfa48-a6bf-4390-8fea-4139b44ead4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 17.7 GiB for an array with shape (39083, 121733) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m y \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Split Data\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Build LSTM Model\u001b[39;00m\n\u001b[0;32m     32\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mword_index) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\CS4248-NLP_Project\\nlpenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\CS4248-NLP_Project\\nlpenv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2683\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2679\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m   2681\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[1;32m-> 2683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2685\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\n\u001b[0;32m   2686\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2687\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\CS4248-NLP_Project\\nlpenv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2685\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2679\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m   2681\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2684\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m-> 2685\u001b[0m         (\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m, _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2686\u001b[0m     )\n\u001b[0;32m   2687\u001b[0m )\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\CS4248-NLP_Project\\nlpenv\\Lib\\site-packages\\sklearn\\utils\\__init__.py:411\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _polars_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\CS4248-NLP_Project\\nlpenv\\Lib\\site-packages\\sklearn\\utils\\__init__.py:208\u001b[0m, in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    207\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m array[:, key]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 17.7 GiB for an array with shape (39083, 121733) and data type int32"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your pandas DataFrame with a column named 'text' containing the sentences\n",
    "# and a column named 'label_column' containing the labels\n",
    "# Example DataFrame:\n",
    "# df = pd.DataFrame({'text': [\"This is sentence 1.\", \"Another sentence.\", \"Yet another sentence.\"],\n",
    "#                    'label_column': [0, 1, 1]})\n",
    "\n",
    "X = df[1].values\n",
    "y = df[0].values\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Padding\n",
    "max_sequence_length = 100 # max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# Convert to Numeric\n",
    "X = padded_sequences\n",
    "y = y\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build LSTM Model\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 100  # Adjust as needed\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "model.add(LSTM(units=128, implementation=2))  # Disable CuDNN\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define a data generator\n",
    "def data_generator(X, y, batch_size):\n",
    "    num_samples = X.shape[0]\n",
    "    while True:\n",
    "        indices = np.random.permutation(np.arange(num_samples))\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_indices = indices[i:i+batch_size]\n",
    "            yield X[batch_indices], y[batch_indices]\n",
    "\n",
    "# Train Model with Data Generator\n",
    "batch_size = 32\n",
    "steps_per_epoch = len(X_train) // batch_size\n",
    "train_generator = data_generator(X_train, y_train, batch_size)\n",
    "\n",
    "# Train Model with Generator\n",
    "model.fit(train_generator, epochs=10, steps_per_epoch=steps_per_epoch, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred = model.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"F1 score (macro):\", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35037039-7f05-47bb-8cbd-fd68d0679300",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19d11451-f66d-44db-974d-f63a16aa34af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x260 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(model, X_train)\n",
    "shap_values = explainer.shap_values(X_test[50:100])\n",
    "shap.summary_plot(shap_values, X_test[50:100], max_display=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d75db457-040a-49bb-9523-ce8490d090be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '01', ..., 'zone', 'zones', 'zoo'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c193552b-1454-4e88-b526-fa28bdfe2692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39083, 10000)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values[0].shape\n",
    "X_test.shape\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04b75ef8-5554-4f45-ac74-6e98684053fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 2 with shape (10000, 4, 4) and arg 3 with shape (10000,).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Plot the bar graph\u001b[39;00m\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m---> 13\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbarh\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msorted_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msorted_shap_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mskyblue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39myticks(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sorted_indices)), sorted_indices)\n\u001b[0;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage Absolute SHAP Value\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\CS4248-NLP_Project\\nlpenv\\Lib\\site-packages\\matplotlib\\pyplot.py:2783\u001b[0m, in \u001b[0;36mbarh\u001b[1;34m(y, width, height, left, align, data, **kwargs)\u001b[0m\n\u001b[0;32m   2772\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mbarh)\n\u001b[0;32m   2773\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbarh\u001b[39m(\n\u001b[0;32m   2774\u001b[0m     y: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2781\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2782\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BarContainer:\n\u001b[1;32m-> 2783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbarh\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2784\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2785\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2786\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2787\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2788\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2789\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2790\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2791\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\CS4248-NLP_Project\\nlpenv\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:2701\u001b[0m, in \u001b[0;36mAxes.barh\u001b[1;34m(self, y, width, height, left, align, data, **kwargs)\u001b[0m\n\u001b[0;32m   2582\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2583\u001b[0m \u001b[38;5;124;03mMake a horizontal bar plot.\u001b[39;00m\n\u001b[0;32m   2584\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2698\u001b[0m \u001b[38;5;124;03m:doc:`/gallery/lines_bars_and_markers/horizontal_barchart_distribution`.\u001b[39;00m\n\u001b[0;32m   2699\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2700\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhorizontal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 2701\u001b[0m patches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbottom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2702\u001b[0m \u001b[43m                   \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2703\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m patches\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\CS4248-NLP_Project\\nlpenv\\Lib\\site-packages\\matplotlib\\__init__.py:1478\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1475\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1478\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1480\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1481\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1482\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\CS4248-NLP_Project\\nlpenv\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:2461\u001b[0m, in \u001b[0;36mAxes.bar\u001b[1;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[0;32m   2458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m yerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2459\u001b[0m         yerr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_dx(yerr, y0, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_yunits)\n\u001b[1;32m-> 2461\u001b[0m x, height, width, y, linewidth, hatch \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2462\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make args iterable too.\u001b[39;49;00m\n\u001b[0;32m   2463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2465\u001b[0m \u001b[38;5;66;03m# Now that units have been converted, set the tick locations.\u001b[39;00m\n\u001b[0;32m   2466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orientation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\CS4248-NLP_Project\\nlpenv\\Lib\\site-packages\\numpy\\lib\\stride_tricks.py:540\u001b[0m, in \u001b[0;36mbroadcast_arrays\u001b[1;34m(subok, *args)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;66;03m# nditer is not used here to avoid the limit of 32 arrays.\u001b[39;00m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Otherwise, something like the following one-liner would suffice:\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;66;03m# return np.nditer(args, flags=['multi_index', 'zerosize_ok'],\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;66;03m#                  order='C').itviews\u001b[39;00m\n\u001b[0;32m    538\u001b[0m args \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray(_m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, subok\u001b[38;5;241m=\u001b[39msubok) \u001b[38;5;28;01mfor\u001b[39;00m _m \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m--> 540\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(array\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m shape \u001b[38;5;28;01mfor\u001b[39;00m array \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;66;03m# Common case where nothing needs to be broadcasted.\u001b[39;00m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\CS4248-NLP_Project\\nlpenv\\Lib\\site-packages\\numpy\\lib\\stride_tricks.py:422\u001b[0m, in \u001b[0;36m_broadcast_shape\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the shape of the arrays that would result from broadcasting the\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;124;03msupplied arrays against each other.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# consistently\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;66;03m# unfortunately, it cannot handle 32 or more arguments directly\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;28mlen\u001b[39m(args), \u001b[38;5;241m31\u001b[39m):\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;66;03m# ironically, np.broadcast does not properly handle np.broadcast\u001b[39;00m\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;66;03m# objects (it treats them as scalars)\u001b[39;00m\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;66;03m# use broadcasting to avoid allocating the full array\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 2 with shape (10000, 4, 4) and arg 3 with shape (10000,)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69629aa0-c9b1-4f56-8107-d0351119de63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
